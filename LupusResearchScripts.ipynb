{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CleanGWASdata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPuGBG847U1OI6ImXOj6/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/briannamathre/LupusResearch/blob/master/LupusResearchScripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPVwbo5J4ipy"
      },
      "source": [
        "Here I am filitering the dataset to have the desired columns and the correct \n",
        "context. The filtered dataframe will then be writen to a file named \"filtered_data.csv\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZW-PfcWSkMH"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#Read in the original CSV\n",
        "df = pd.read_csv('filtered_data_unprocessed.csv') \n",
        "\n",
        "#Only keep the following columns from the dataframe\n",
        "df = df[['SNPS','MAPPED_GENE','DOWNSTREAM_GENE_ID','UPSTREAM_GENE_ID','SNP_GENE_IDS','CONTEXT','MAPPED_TRAIT', 'P-VALUE']]\n",
        "\n",
        "#Ensure that we are only keeping the SNPs with the following context:\n",
        "#This command will return TRUE or FALSE whether the column contains these values\n",
        "list_Valid_Context = ['intergenic_variant','3_prime_UTR_variant','5_prime_UTR_variant','intron_variant','regulatory_region_variant','TF_binding_site_variant']\n",
        "\n",
        "#Filter through the dataframe according to the filter. \n",
        "df = df[df.CONTEXT.isin(list_Valid_Context)]\n",
        "\n",
        "#Send our new-filtered data to a new csv file. \n",
        "df.to_csv('filtered_data.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO48lA-n6TmD"
      },
      "source": [
        "To get the number of variants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHda-uAW52fT",
        "outputId": "df94ba1c-e974-4e18-9b59-b1bee2901500"
      },
      "source": [
        "#This will print the number of variants that we will actually be analyzing. \n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Uo-6zywJXTN"
      },
      "source": [
        "This code will allow me to put all of the rsIDs into a list. After the list is created all of these will be added into a set so that only unique values are counted. The set will then be converted back into a list so that further analysis can be made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLn-J1hoJO04",
        "outputId": "a879de6e-3bf7-41d9-f440-c140b2da9af9"
      },
      "source": [
        "#Here we will take the SNPs column and add it to a list.\n",
        "contextList = df.SNPS.tolist()\n",
        "\n",
        "#Make sure the length observed here was the same length as we found before.\n",
        "print(len(contextList))\n",
        "\n",
        "#Change the list into a set to get rid of duplicates\n",
        "contextList= list(set(contextList))\n",
        "\n",
        "#Record the number of non-duplicate variants. \n",
        "print(len(contextList))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "682\n",
            "521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Eh_ivDAWM0"
      },
      "source": [
        "This code will create text files that have 100 SNPS in them. This is becuase the tool PhenolScanner can only accept 100 SNPs at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsJH5M9mGZt1"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# We will loop through the data 5 times.\n",
        "for i in range((int(len(contextList)/100))):\n",
        "  start = i * 100 #Calculate the starting point\n",
        "  end = ((i + 1) * 100) #Calculate the ending point\n",
        "  #Create and open a new text flle\n",
        "  f = open(str(start) + \"_\" + str(end) + \".txt\", \"a\")\n",
        "  #Parse through the list using the calculated start/end points\n",
        "  newList=contextList[start:end]\n",
        "  #Using each rsID, make sure that it begins with rs and if it does,\n",
        "  # write it to the file\n",
        "  for item in newList:\n",
        "    x = item.startswith(\"rs\")\n",
        "    if x == True:\n",
        "      f.write(item + \"\\n\")\n",
        "    else: \n",
        "      pass\n",
        "  #After we have finished adding all of the rsIDs to the file, close it.\n",
        "  f.close()\n",
        "\n",
        "#This is the final text file, which does not contain 100 SNPSs\n",
        "f = open('500_end.txt', \"a\")\n",
        "#Get the final 21 rsIDs in the list\n",
        "newList=contextList[500:]\n",
        "for item in newList:\n",
        "    x = item.startswith(\"rs\")\n",
        "    if x == True:\n",
        "      f.write(item + \"\\n\")\n",
        "    else: \n",
        "      pass\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzRTfwyGJh1U"
      },
      "source": [
        "Double check to make sure each file has 100 or SNPS in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrKiYpQOAtZt",
        "outputId": "217aa2dd-27ec-437c-ae11-3eb9aac54e94"
      },
      "source": [
        "fileNames = [\"0_100.txt\",\"100_200.txt\",\"200_300.txt\",\"300_400.txt\",\"400_500.txt\",\"500_end.txt\"]\n",
        "all_rsIDs = []\n",
        "for files in fileNames:\n",
        "  fileName = open(files, \"r\")\n",
        "  fileItems = 0\n",
        "  for line in fileName:\n",
        "    all_rsIDs.append(line)\n",
        "    fileItems += 1\n",
        "  print(fileItems)\n",
        "\n",
        "rsIDs = pd.DataFrame(all_rsIDs)\n",
        "print(len(rsIDs))\n",
        "rsIDs.to_csv(\"allRSids.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "21\n",
            "521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUYfCR7QbDOM"
      },
      "source": [
        "This file will take all of the UP_STREAM genes, the DOWN_STREAM genes\n",
        "and SNP_Gene Ids and will put them all into one list. After this list\n",
        "is created, duplicates will be removed, and then each gene will be written\n",
        "on a new line in a text file. There were 525 unique genes identified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs9STgNd-gak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb1557c-e9bb-405a-95b6-3cff3e406149"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "SNP_Gene_List = df.SNP_GENE_IDS.tolist()\n",
        "Down_Stream_Genes = df.DOWNSTREAM_GENE_ID.tolist()\n",
        "Up_Stream_Genes = df.UPSTREAM_GENE_ID.tolist()\n",
        "print(len(SNP_Gene_List))\n",
        "print(len(Down_Stream_Genes))\n",
        "print(len(Up_Stream_Genes))\n",
        "SNP_Gene_List.extend(Down_Stream_Genes)\n",
        "SNP_Gene_List.extend(Up_Stream_Genes)\n",
        "print(len(SNP_Gene_List))\n",
        "\n",
        "f = open(\"AllGenes.txt\", \"a\")\n",
        "geneList = []\n",
        "for item in SNP_Gene_List:\n",
        "  if str(item) == 'nan':\n",
        "    pass\n",
        "  else: \n",
        "    if (len(str(item)) > 16):\n",
        "      gene_IDS = str(item)\n",
        "      gene_IDS = gene_IDS.split(\", \")\n",
        "      for thing in gene_IDS:\n",
        "        geneList.append(str(thing))\n",
        "    else: \n",
        "      geneList.append(str(item))\n",
        "\n",
        "f = open(\"AllGenes.txt\", \"a\")\n",
        "geneList = list(set(geneList))\n",
        "print(len(geneList))\n",
        "for gene in geneList:\n",
        "  f.write(str(gene) + \"\\n\")\n",
        "f.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "682\n",
            "682\n",
            "682\n",
            "2046\n",
            "525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqCO92gU5UVz"
      },
      "source": [
        "Here we will take the eQTL results files and then combine them all into one file. \n",
        "We will take all of the results and extract the expressed gene based off of the rsID. We will then check to see if that gene has already been considered. If it has, then we skip it, otherwise we add that row to our \"total_genes.csv\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Z3TxqG5c3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61069be0-805e-4b10-fd4a-ca59644b37df"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#You will need to download these files from PhenoScanner after you have ran the analysis.\n",
        "files = [\"0_100_PhenoScanner_eQTL.csv\",\"100_200_PhenoScanner_eQTL.csv\",\"200_300_PhenoScanner_eQTL.csv\",\"300_400_PhenoScanner_eQTL.csv\",\"400_500_PhenoScanner_eQTL.csv\",\"500_end_PhenoScanner_eQTL.csv\"]\n",
        "\n",
        "results = pd.DataFrame()\n",
        "\n",
        "#Combine all of the results from all of the files into one file\n",
        "for file1 in files:\n",
        "  df = pd.read_csv(file1) \n",
        "  results = results.append(df)\n",
        "\n",
        "#Now sort those combined files\n",
        "final_results = results.sort_values(by=[\"p\"])\n",
        "final_results.to_csv(\"eQTL_Combined.csv\")\n",
        "\n",
        "res = [] \n",
        "total_unique = []\n",
        "#Here we will find the number of unique genes expressed across all of the files\n",
        "for index, row in final_results.iterrows():\n",
        "    expressed_gene = row['exp_gene']\n",
        "    if expressed_gene not in res: \n",
        "      res.append(expressed_gene)\n",
        "      total_unique.append(row)\n",
        "    \n",
        "total_unique = pd.DataFrame(total_unique)\n",
        "\n",
        "total_unique.to_csv(\"total_unique_genes.csv\")\n",
        "print(len(total_unique))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLd608Pq1E9p"
      },
      "source": [
        "Here we will take the total unique genes, and I will pull out all of the rsIds from the original list. We will take the eQTL results that have all of the total unique genes. We will use all of the known rsIDs from the original data and will compare them against the eQTL results. This program will return the number of rsIDs that were found in both the rsIDS from the GWAS catalog and from the eQTL results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3Yr_08q1EqJ",
        "outputId": "e1a77029-0089-4873-ce95-88b0b0a363c2"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "eqtl_results = pd.read_csv(\"total_unique_genes.csv\") \n",
        "\n",
        "#The \"allRSids.csv\" file can be found in the Original_Data folder on Github\n",
        "rsids = pd.read_csv(\"allRSids.csv\")\n",
        "rsids = rsids[\"0\"].to_list()\n",
        "clean_rsIDs = []\n",
        "for rsID in rsids:\n",
        "  rsID = rsID[:-1]\n",
        "  clean_rsIDs.append(rsID)\n",
        "\n",
        "total_found = []\n",
        "for index, row in eqtl_results.iterrows():\n",
        "    rsid = row[\"rsid\"]\n",
        "    if rsid in clean_rsIDs:\n",
        "      total_found.append(row)\n",
        "\n",
        "total_found = pd.DataFrame(total_found)\n",
        "total_found = total_found[\"rsid\"]\n",
        "\n",
        "total_found_set=set(total_found)\n",
        "print(total_found_set)\n",
        "print(len(total_found_set))\n",
        "results = []\n",
        "final_results = []\n",
        "for index, row in eqtl_results.iterrows():\n",
        "  for r in total_found:\n",
        "    rsid = row[\"rsid\"]\n",
        "    if (rsid not in final_results) and rsid == r:\n",
        "      results.append(row)\n",
        "      final_results.append(r)\n",
        "\n",
        "print(len(results))\n",
        "results = pd.DataFrame(results)\n",
        "results.to_csv(\"eQTL_genes_found.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'rs2041670', 'rs150518861', 'rs4958880', 'rs4748857', 'rs10946940', 'rs79404002', 'rs6871748', 'rs351758', 'rs2275247', 'rs427221', 'rs6804441', 'rs58688157', 'rs1405209', 'rs2688608', 'rs12736195', 'rs2238573', 'rs12664535', 'rs11697848', 'rs6679677', 'rs17083844', 'rs1150754', 'rs7197475', 'rs3087243', 'rs835573', 'rs2431099', 'rs2187668', 'rs6601327', 'rs58721818', 'rs11154801', 'rs4963128', 'rs1048257', 'rs10276619', 'rs4795774', 'rs5986948', 'rs7579944', 'rs564799', 'rs5754467', 'rs11887156', 'rs931127', 'rs6538678', 'rs2111485', 'rs8058578', 'rs869310', 'rs558702', 'rs17552904', 'rs2303745', 'rs131654', 'rs3794060', 'rs2396545', 'rs3129716', 'rs1217393', 'rs11264750', 'rs1170426', 'rs2015407', 'rs180977001', 'rs1167796', 'rs11085727', 'rs6590330', 'rs10142203', 'rs1590381', 'rs4690055', 'rs9394274', 'rs7329174', 'rs1780813', 'rs11724582', 'rs11150610', 'rs4252665', 'rs12971295', 'rs11117433', 'rs12565776', 'rs1946007', 'rs1535001', 'rs1385374', 'rs564976', 'rs10889681', 'rs76725306', 'rs9271366', 'rs7172677', 'rs17881940', 'rs17807624', 'rs268134', 'rs12917712', 'rs6445975', 'rs497273', 'rs1478897', 'rs4697651', 'rs36014129', 'rs73366469', 'rs2297550', 'rs3768792', 'rs11243676', 'rs12706861', 'rs1378942', 'rs11066301', 'rs17321999', 'rs4739134', 'rs2669010', 'rs2196171', 'rs12531540', 'rs820077', 'rs340630', 'rs10057690', 'rs1432296', 'rs2928402', 'rs34330', 'rs76246107', 'rs2301271', 'rs10912578', 'rs489574', 'rs4745876', 'rs3135394', 'rs4355385', 'rs10857712', 'rs4639966', 'rs9652601', 'rs4948496', 'rs3821236', 'rs6738825', 'rs9398235', 'rs1885889', 'rs3734266', 'rs7325747', 'rs11951576', 'rs11644034', 'rs2550333', 'rs1874252', 'rs13260060', 'rs56886418', 'rs1913517', 'rs4622329', 'rs2855772', 'rs28411034', 'rs11860650', 'rs9603612', 'rs7819602', 'rs2618444', 'rs1887428', 'rs10521318', 'rs35789010', 'rs2548279', 'rs9462027', 'rs12753920', 'rs3914167', 'rs4675354', 'rs3024505', 'rs2984920', 'rs11231824', 'rs7601754', 'rs11101442', 'rs4850410', 'rs2647012', 'rs2941509', 'rs7333671', 'rs17484292', 'rs5754217', 'rs7795074', 'rs223883', 'rs7090925', 'rs2289583', 'rs10954214', 'rs7708392', 'rs6671847', 'rs6084875', 'rs2980512', 'rs10762171', 'rs7897633', 'rs3024493', 'rs12620999', 'rs12993006', 'rs643955', 'rs6688100', 'rs1151988', 'rs7031325', 'rs13069553', 'rs4728142', 'rs10018951', 'rs6659932', 'rs3131379', 'rs10737562', 'rs4388254', 'rs7726414', 'rs6695567', 'rs586995', 'rs34725611', 'rs979233', 'rs877819', 'rs13101828', 'rs6697139', 'rs12615624', 'rs1364989', 'rs9271100', 'rs13116227', 'rs3934007', 'rs10774625', 'rs4917385', 'rs10753074', 'rs4978037', 'rs494003', 'rs916287', 'rs11655550', 'rs36023980', 'rs13344313', 'rs10028805', 'rs11073328', 'rs2431098', 'rs7444', 'rs967616', 'rs849142', 'rs2732549', 'rs2283790', 'rs10905718', 'rs7597017', 'rs4641121', 'rs12444486', 'rs212407', 'rs4930194', 'rs6131014', 'rs956237', 'rs10954650', 'rs61839660', 'rs2041862', 'rs9889107', 'rs653178', 'rs11590283', 'rs2953898', 'rs2618476', 'rs12822507', 'rs2384991', 'rs1635852', 'rs6889239', 'rs10254284', 'rs9852465', 'rs10798176', 'rs2222631', 'rs4901847', 'rs56154925', 'rs6677604', 'rs4810485', 'rs9267972', 'rs4917014', 'rs2061831', 'rs13385731', 'rs7411387', 'rs9782955', 'rs7929541', 'rs6486730', 'rs11227302', 'rs3122605', 'rs112006329', 'rs2051549', 'rs1170436', 'rs10892286', 'rs1437466', 'rs911263', 'rs330048', 'rs4690229', 'rs11578098', 'rs10995092', 'rs1039917', 'rs332398', 'rs2736345', 'rs2092540', 'rs10911628', 'rs548234', 'rs11059919', 'rs4902562', 'rs4859711', 'rs1966115', 'rs10845606', 'rs1150755', 'rs387619', 'rs13389408', 'rs229541', 'rs3750310', 'rs3747093', 'rs8105429', 'rs9899849', 'rs12537284', 'rs13277113', 'rs11057864', 'rs2736340', 'rs13332649', 'rs597808', 'rs1547624', 'rs112846137', 'rs6438700', 'rs9303277', 'rs12574073', 'rs3862260', 'rs12548184', 'rs17301013', 'rs3757387', 'rs74290525', 'rs930297', 'rs3733345', 'rs9387400', 'rs958476', 'rs6074813', 'rs525410', 'rs597325', 'rs10798269', 'rs1028488', 'rs6662618', 'rs12711490', 'rs1463525', 'rs169080', 'rs1429411', 'rs147622113', 'rs8072449', 'rs4852324', 'rs2381401', 'rs11788118', 'rs744600', 'rs17630235', 'rs12636784', 'rs7683537', 'rs12599402', 'rs9311676', 'rs76413021', 'rs10245867', 'rs7200786', 'rs2176082', 'rs9937837', 'rs3828069', 'rs6946131', 'rs8012283', 'rs6049839', 'rs3795310', 'rs1150753', 'rs11085725', 'rs10466455', 'rs5029924', 'rs12148050', 'rs7941765', 'rs11185603', 'rs12068671', 'rs2797780', 'rs11679484', 'rs2663052', 'rs4956211', 'rs2764208', 'rs2453042', 'rs34572943', 'rs274068', 'rs9630991', 'rs223889', 'rs9275572', 'rs137956', 'rs11629434', 'rs2478118', 'rs2269368', 'rs729302', 'rs3130320', 'rs3760667', 'rs4149228', 'rs2736337', 'rs10911363', 'rs353592', 'rs909788'}\n",
            "359\n",
            "359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0cew9zkjesQ"
      },
      "source": [
        "Here we will take the Case vs. Control studies and extract the columns with the gene name. The top 1000 will be taken from each file and combined into one master file. The top 1000 genes will be taken. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdDW3DqVjwaq"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#You will need to run the analyses on GEO2R based off of given parameters in the \n",
        "# Materials/Methods section. The results will need to be downloaded from GEO2R\n",
        "files = ['GSE11907.top.table.csv',\"GSE10325.top.table.csv\",\"GSE39088.top.table.csv\",\n",
        "         \"GSE45291.top.table.csv\",\"GSE49454.top.table.csv\",\"GSE51997.top.table.csv\"]\n",
        "\n",
        "case_vs_control = pd.DataFrame()\n",
        "for file1 in files:\n",
        "  df = pd.read_csv(file1) \n",
        "  #Take the top 4000 results\n",
        "  df = df[:4000]\n",
        "  case_vs_control = case_vs_control.append(df)\n",
        "\n",
        "#Take all of the results, sort them by p-value, and then add all of the results\n",
        "# to a new file with the combined results. \n",
        "final_cvc_results = case_vs_control.sort_values(by=[\"P.Value\"])\n",
        "final_cvc_results.to_csv(\"CVC_Combined.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzY5gWcbjcAc"
      },
      "source": [
        "Now we will take the combined results table and get all of the unique gene names, in order. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybmSDqBCjijn"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "results = pd.read_csv(\"CVC_Combined.csv\") \n",
        "\n",
        "\n",
        "final_results = results.sort_values(by=[\"adj.P.Val\"])\n",
        "\n",
        "exp_genes = final_results['Gene.symbol']\n",
        "\n",
        "res = [] \n",
        "for i in exp_genes: \n",
        "    if i not in res and str(i) != \"nan\": \n",
        "        res.append(i) \n",
        "\n",
        "res = res[:1000]\n",
        "caseVcontrol_data = pd.DataFrame(res)\n",
        "caseVcontrol_data.to_csv(\"Top_1000_results.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE2cHcrJctZg"
      },
      "source": [
        "Now I will take the KEGG pathway enriched table and separate the userID's so that they have their associated p-value which each gene. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "***DO WE USE THIS??***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23hB9WbHcs4-"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#Here you will need to get these results, using the specified settings,\n",
        "# and by downloading and using the given file. \n",
        "enrichment = pd.read_csv(\"enrichment_results_wg_result1614031939.csv\") \n",
        "\n",
        "\n",
        "dic = dict()\n",
        "\n",
        "#key as existing values and value as the p-value\n",
        "for index, row in enrichment.iterrows():\n",
        "    pValue = row[\"pValue\"]\n",
        "    values = []\n",
        "    values.append(pValue)\n",
        "    keys = row[\"userId\"].split(\";\")\n",
        "    for key in keys:\n",
        "      if key not in dic:\n",
        "        dic[key] = values\n",
        "      else: \n",
        "        continue\n",
        "        #we can use this code if we want ALL of the pvalues they were associated with, \n",
        "        #   not just the lowest p-Value\n",
        "        #items = list(dic[key])\n",
        "        #items.append(pValue)\n",
        "        #dic[key] = items\n",
        "\n",
        "df = pd.DataFrame(list(dic.items()),columns = ['EnsemblID','pValue']) \n",
        "\n",
        "df.to_csv(\"enrichment_ensembl_pvalues.csv\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnKfLHtxW_WB"
      },
      "source": [
        "Here is to get the top 10 KEGG pathways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTnBC0JVNz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8315ca8-308a-45d6-bb8c-aeab8bb86ab7"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#To get these file, you should run WebGestalt using the specified settings,\n",
        "# and by downloading the file that begins with \"enrichment_results_wg_\".\n",
        "# After downloading this file it was renamed. \n",
        "enrichment_KEGG = pd.read_csv(\"KEGG_Initial_Results.csv\")\n",
        "enrichment_KEGG = enrichment_KEGG[[\"geneSet\",\"description\",\"size\",\"expect\", \"pValue\",\"FDR\"]]\n",
        "top_20_results_KEGG = []\n",
        "for index, row in enrichment_KEGG.iterrows():\n",
        "  top_20_results_KEGG.append(row)\n",
        "  \n",
        "print(len(top_20_results_KEGG))\n",
        "top_20_results_KEGG = pd.DataFrame(top_20_results_KEGG[:20])\n",
        "\n",
        "top_20_results_KEGG.to_csv(\"KEGG_Top_20.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW6lSPjdXGQv"
      },
      "source": [
        "Here is to get the top 20 Biological Processes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCC7NK0BXEwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f24998-e886-48c7-ab72-05d172fcbbff"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "enrichment_biological = pd.read_csv(\"Biological_Processes_Initial_Results.csv\")\n",
        "\n",
        "enrichment_biological = enrichment_biological[[\"geneSet\",\"description\",\"size\",\"expect\", \"pValue\",\"FDR\"]]\n",
        "top_20_results_biological = []\n",
        "for index, row in enrichment_biological.iterrows():\n",
        "  top_20_results_biological.append(row)\n",
        "\n",
        "print(len(top_20_results_biological))\n",
        "    \n",
        "top_20_results_biological = pd.DataFrame(top_20_results_biological[:20])\n",
        "\n",
        "top_20_results_biological.to_csv(\"Biological_Processes_Top_20.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czztpthY6Wg"
      },
      "source": [
        "Here is the code for the Top 20 cellular components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzctSDS6Y963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04def2b5-8c61-4704-8827-7c82afbde871"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "enrichment_cellular = pd.read_csv(\"Cellular_Components_Initial_Results.csv\")\n",
        "\n",
        "enrichment_cellular = enrichment_cellular[[\"geneSet\",\"description\",\"size\",\"expect\", \"pValue\",\"FDR\"]]\n",
        "top_20_results_cellular = []\n",
        "for index, row in enrichment_cellular.iterrows():\n",
        "  top_20_results_cellular.append(row)\n",
        "    \n",
        "print(len(top_20_results_cellular))\n",
        "top_20_results_cellular = pd.DataFrame(top_20_results_cellular[:20])\n",
        "\n",
        "top_20_results_cellular.to_csv(\"Cellular_Components_Top_20.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5r40zvmZmpk"
      },
      "source": [
        "Here is the code for the Top 20 molecular functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lavgoqhBZrgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f8eddc-9830-41d6-d331-98db9347c82d"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "enrichment_molecular = pd.read_csv(\"Molecular_Function_Initial_Results.csv\")\n",
        "\n",
        "enrichment_molecular = enrichment_molecular[[\"geneSet\",\"description\",\"size\",\"expect\", \"pValue\",\"FDR\"]]\n",
        "top_20_results_molecular = []\n",
        "for index, row in enrichment_molecular.iterrows():\n",
        "  top_20_results_molecular.append(row)\n",
        "    \n",
        "print(len(top_20_results_molecular))\n",
        "top_20_results_molecular = pd.DataFrame(top_20_results_molecular[:20])\n",
        "\n",
        "top_20_results_molecular.to_csv(\"Molecular_Functions_Top_20.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBkXQTeJ62Aw"
      },
      "source": [
        "Here I will take all of the identified risk genes, and see how many of those were in the CVC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXV_nIIr62ZZ",
        "outputId": "0fc7845f-a73d-4535-f77b-39f449bb30b2"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "mapped_genes_df = pd.read_csv(\"filtered_data.csv\")\n",
        "individual_genes = []\n",
        "for index, row in mapped_genes_df.iterrows():\n",
        "    genes = row[\"MAPPED_GENE\"].split(\",\")\n",
        "    for item in genes:\n",
        "      secondSplit = item.split(\"-\")\n",
        "      for gene in secondSplit:\n",
        "          if (\".\" not in gene) and (gene not in individual_genes):\n",
        "            individual_genes.append(gene)\n",
        "print(individual_genes)\n",
        "\n",
        "#the list individual genes has all of the mapped gene names from the original snps\n",
        "CVC_data = pd.read_csv(\"CVC_Combined.csv\")\n",
        "\n",
        "risk_genes_in_CVC = []\n",
        "total_genes_in_CVC = set()\n",
        "rows = []\n",
        "for index, row in CVC_data.iterrows():\n",
        "  expressed_gene = row['Gene.symbol']\n",
        "  total_genes_in_CVC.add(expressed_gene)\n",
        "  if expressed_gene in individual_genes:\n",
        "      risk_genes_in_CVC.append(expressed_gene)\n",
        "      rows.append(row)\n",
        "\n",
        "CVC_results = pd.DataFrame(rows)\n",
        "\n",
        "CVC_results.to_csv(\"CVC_risk_genes.csv\")\n",
        "CVC_results = CVC_results.sort_values(by=[\"adj.P.Val\"])\n",
        "print(len(total_genes_in_CVC))\n",
        "print(len(risk_genes_in_CVC))\n",
        "print(risk_genes_in_CVC)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['STAT4', 'TNPO3', 'BLK', ' IRF5', 'XKR6', 'GLT1D1', 'MTCO3P1 ', ' SNRPC', 'CD83P1 ', ' RNU6', '471P', 'LAMC1 ', ' LAMC2', ' EDEM3', 'TEX51 ', ' RNU7', '182P', 'RNU6', '546P ', 'CNTN6 ', ' RPL23AP38', 'C2', ' C2', ' TNPO3', 'MTG1', ' APIP', 'FAM98B', 'RN7SKP181 ', ' LINC02253', 'ITGAM', 'MED1 ', ' CDK12', ' RASSF2', 'KRT18P4 ', '147P', 'HLA', 'DQB2', ' HLA', 'TNFAIP3', 'WDFY4', ' RPL7P13', 'COX10', 'AS1', 'TNXB', ' TNXB', 'SLC1A7 ', ' LINC00578', 'TMC2', ' BLK', 'LAMC2', 'UBE2L3', 'RNA5SP73 ', ' LINC01701', 'DQA1', 'RCC2P8 ', ' COL25A1', 'MIR3142HG', 'PHRF1', ' PHRF1', 'TSBP1', 'NAALADL2', 'AS2', ' NAALADL2', 'DQB1 ', ' MTCO3P1', 'ELF1', 'ETS1', ' GHR', 'NEGR1', ' NEGR1', 'IT1', 'NTNG2', 'MSH5', ' MSH5', 'SAPCD1', 'RNU6ATAC13P ', ' HIVEP3', 'CRB1', 'LNC', 'LBCS', ' RPL35AP19', 'PRPF18', 'CCDC38', ' SNRPF', 'NIN', 'SLC5A11', 'ARMH4', 'ANKRD44', 'PRKG1', 'LINC01624 ', ' DLL1', ' RN7SKP82', 'CHIA', 'DRD2 ', ' TMPRSS5', ' ANKRD44', 'SCARB1', 'LINC02835 ', ' EPHA5', 'CAMK1D', 'BARX2', 'LINC02331', 'LINC01739', ' LINC02331', 'LINC01019', 'HIPK2', 'TRIM9 ', ' TMX1', 'EPHX1', 'RPL31P11 ', 'AP5B1', ' PTPRC', 'SRGAP2 ', ' IKBKE', 'H3P5 ', ' LBH', 'LBH', 'LPP', 'BACH2', 'GTF2IRD1', 'JAK2', 'ZFP90', 'ATXN1', 'LINC01967', 'LINC00271', 'SPRED2', 'FAP ', ' IFIH1', 'IKZF2', 'IRF5', ' TCF7', 'CLEC16A', 'IKZF3', 'UHRF1BP1', 'TNFSF4 ', 'TNIP1', 'ATG5', 'PDHB ', 'IL12A', 'ARID5B', 'PDHX ', 'ATXN2', 'SCAMP5', 'RASGRP3', 'TYK2', 'ANKS1A', 'CDHR5', ' CDHR5', 'JAZF1', 'IL10', 'NR0B1 ', ' CXorf21', ' LINC02528', 'NAPGP2 ', ' MUC21', 'FCGR2A', 'SLC44A4', ' SLC44A4', 'NADSYN1', 'RAD51B', 'MIR8062 ', ' RN7SL547P', ' IL10', 'LYST', ' IKZF2', 'BANK1', 'IL12RB2', 'AHI1', 'LCP1', 'KIT', ' GPR78', 'TRAPPC11', 'RTKN2', 'YDJC ', ' CCDC116', 'PHTF1 ', ' RSBN1', 'SLC15A4', 'GLTPD2 ', ' PSMB6', 'DDO', 'ARHGAP4', 'NCF2', ' SMG7', 'CENPU', 'SPPL3', 'CYCS', 'SPATA48 ', 'KLF12', ' SRRM4', 'TENT4A', 'CD86 ', 'TMEM132C ', ' SLC15A4', 'C10orf67', 'C9', ' DAB2', 'SMYD3', 'ST8SIA4', 'LIMK1 ', ' EIF4H', ' ARHGAP27', ' GRB2', 'TRAF3', 'LRRC25 ', ' SSBP4', 'CDH23', 'FCRL5', 'PLCL1', 'NCOA2', 'STX17', ' NR4A3', ' TM9SF2', 'ARHGAP15', 'IQCN ', ' JUND', 'MTF1', 'CTLA4 ', ' ICOS', 'SLC6A16', 'RERE', 'DSE', 'LINC00824', 'RCBTB1 ', 'TNIP2', ' LINC02498', 'IFNA17 ', ' IFNWP5', 'RABGAP1L', 'IL7R ', 'AFF1', 'LEF1', 'LINC02098 ', ' ETS1', 'DRB1 ', ' WDFY4', ' LRRC18', ' PRR14', 'HIP1', 'PXK', 'CD80', 'FCHSD2 ', 'AHNAK2', 'TMEM187 ', ' IRAK1', 'NOTCH4 ', ' TSBP1', 'ST13P13 ', ' RPEL1', 'CDK18 ', ' RNU2', '19P', 'KDM4C', 'LINC01088', 'HSD3BP5 ', ' ZNF697', 'LINC02520 ', ' MIR3144', 'LINC00208 ', ' GAS1', 'PCNX3 ', ' SIPA1', 'PRPS2', 'SLC12A1', 'SLC22A11 ', ' SLC22A12', 'COG6', 'WAKMAR2', 'DRA', 'FAM171A1 ', ' ITGA8', 'PGPEP1 ', ' GDF15', 'DGUOK', 'CREBL2', ' GPR19', 'CDKN1B', 'DRAM1', 'SCN10A', 'SEZ6L2', 'ABHD8', 'KIAA0319L', 'LINC02832 ', ' LINC01803', 'LINC02539 ', ' WAKMAR2', ' RPL36AP45', 'KALRN', 'MGAT5', 'AP4B1', 'RPL6P8 ', ' ARL14', 'DGKQ', 'SCT ', ' DRD4', 'PTPN11', 'PRR12', 'TCP11', 'ZNF76', 'CCDC113', 'MSRA', ' MSRA', 'C1QTNF6', 'CTNNA3', ' PRDM1', 'TCP11 ', ' SCUBE3', 'SBK1', 'KSR1', 'UBAC2', 'RPS29P10 ', '1145P', 'IL18RAP', 'SKAP2', ' SRCAP', 'SLC25A19 ', 'NOTCH2', 'IL2RA', 'MTCO1P6 ', 'ERBB2', ' MIEN1', 'CLNK', 'RSL24D1P4 ', 'LINC01511', 'RAPH1 ', 'CD40', ' TMEM86B', 'CEPT1', 'CFH', 'VANGL2 ', ' SLAMF6', ' LINC01845', 'RN7SKP62 ', ' ST8SIA4', 'ICA1', 'LINC02694', 'RSPH3', 'TP63', ' IKZF1', 'IFNG', 'ZNF804A ', 'STAT3', ' SYT1', 'CIITA ', ' CLEC16A', 'GALC', 'ENTHD1 ', ' GRAP2', 'LINC01185', 'KDM4B', 'NMNAT2', 'TRAFD1 ', ' HECTD4', 'RPS20', 'DDX6', 'PPARG ', ' TSEN2', 'DPF3', 'IL2 ', ' IL21', 'ARID3A', ' STX17', 'FASLG ', ' SLC25A38P1', 'DARS1', 'TMEM39A', 'RAB23 ', ' PRIM2', 'PVT1', 'IL19', 'EVI5', ' SHROOM3', 'AP5B1 ', ' OVOL1', ' XKR6', 'CSK', 'ELP3', ' SLC22A11', 'PAPOLG', 'RPL13P2 ', ' CD40', 'MIR3678 ', '938P', 'RPL32P23 ', ' RBM17', 'PUSL1', 'SORCS2', ' CCL22', 'BTF3L4P3 ', 'FAM86B3P ', ' PRAG1', 'CARMIL1', 'H2AC3P ', ' H2BP5', 'ETV7', 'CAMK2G ', ' PLAU', 'ILF3', ' PXK', 'RN7SL824P ', ' GFI1', 'MFHAS1', ' MFHAS1', 'MYNN ', ' LRRC34', 'TERT']\n",
            "11226\n",
            "259\n",
            "['JAK2', 'NTNG2', 'HIPK2', 'HIPK2', 'ETS1', 'KDM4B', 'BACH2', 'KDM4B', 'LYST', 'ILF3', 'UBE2L3', 'CD40', 'PTPN11', 'ETS1', 'TNXB', 'DGUOK', 'FCGR2A', 'DDX6', 'DDX6', 'BANK1', 'KDM4B', 'BANK1', 'ETV7', 'BANK1', 'CDHR5', 'LBH', 'ETS1', 'TNIP2', 'NCOA2', 'STAT3', 'PLCL1', 'AP5B1', 'BANK1', 'PRR12', 'JAK2', 'PTPN11', 'PUSL1', 'ETV7', 'LCP1', 'RABGAP1L', 'CDKN1B', 'KLF12', 'ERBB2', 'MTF1', 'DSE', 'HIPK2', 'LBH', 'PTPN11', 'CDHR5', 'HIPK2', 'CSK', 'TNIP1', 'ILF3', 'CREBL2', 'TNIP2', 'KLF12', 'LEF1', 'SORCS2', 'DGUOK', 'IKZF2', 'DRAM1', 'NADSYN1', 'XKR6', 'JAK2', 'CDH23', 'ETV7', 'JAK2', 'EVI5', 'DDX6', 'ANKRD44', 'IKZF3', 'RABGAP1L', 'ATXN2', 'LYST', 'DRAM1', 'ETV7', 'MGAT5', 'EVI5', 'IKZF3', 'CDH23', 'TNIP2', 'TP63', 'NOTCH2', 'ATXN2', 'ELP3', 'LPP', 'RABGAP1L', 'KDM4C', 'IFNG', 'C10orf67', 'DGKQ', 'STAT3', 'CDH23', 'KLF12', 'BACH2', 'NADSYN1', 'KALRN', 'TNXB', 'SBK1', 'NOTCH2', 'LCP1', 'TRAF3', 'HIPK2', 'ANKRD44', 'JAK2', 'RABGAP1L', 'ILF3', 'STAT3', 'SKAP2', 'SKAP2', 'TNIP1', 'SKAP2', 'NOTCH2', 'RSPH3', 'DDX6', 'TNIP2', 'KIAA0319L', 'UHRF1BP1', 'ERBB2', 'ZFP90', 'ICA1', 'KIAA0319L', 'MTF1', 'SPPL3', 'PHRF1', 'NCF2', 'LPP', 'ST8SIA4', 'MTF1', 'LCP1', 'KLF12', 'TNXB', 'IL10', 'ATG5', 'DPF3', 'STAT3', 'KIT', 'ELF1', 'ATG5', 'KIT', 'RERE', 'CD40', 'JAK2', 'LBH', 'KALRN', 'CD80', 'STAT3', 'NTNG2', 'SPRED2', 'BLK', 'TNPO3', 'CLEC16A', 'ITGAM', 'IRF5', 'IKZF2', 'UBE2L3', 'MFHAS1', 'ETV7', 'ILF3', 'KDM4C', 'CEPT1', 'ITGAM', 'ERBB2', 'TNFAIP3', 'RABGAP1L', 'PRPS2', 'HIPK2', 'IL19', 'CD80', 'FCGR2A', 'DGKQ', 'ARHGAP4', 'HIPK2', 'STAT3', 'BACH2', 'MGAT5', 'STAT3', 'KLF12', 'CDH23', 'STX17', 'TNXB', 'KLF12', 'ICA1', 'ARHGAP4', 'RABGAP1L', 'ETV7', 'STAT3', 'DDX6', 'LCP1', 'STAT4', 'LBH', 'CDHR5', 'AFF1', 'NIN', 'LBH', 'C1QTNF6', 'PTPN11', 'KIAA0319L', 'SCARB1', 'TNFAIP3', 'STAT3', 'AP4B1', 'AP4B1', 'PAPOLG', 'TRAF3', 'ANKRD44', 'KIT', 'KALRN', 'BANK1', 'LYST', 'RPS20', 'CTNNA3', 'AP5B1', 'ILF3', 'DSE', 'AHI1', 'CD40', 'AFF1', 'PTPN11', 'SLC15A4', 'MGAT5', 'ST8SIA4', 'STAT3', 'ATG5', 'CYCS', 'TNIP2', 'ATXN1', 'UBE2L3', 'ELP3', 'DGUOK', 'TNFAIP3', 'TNFAIP3', 'KSR1', 'SCARB1', 'ARHGAP4', 'RERE', 'RABGAP1L', 'PRPF18', 'ATG5', 'ICA1', 'TRAF3', 'DGUOK', 'TP63', 'CARMIL1', 'CDHR5', 'STX17', 'NMNAT2', 'PTPN11', 'CENPU', 'AHNAK2', 'ABHD8', 'IL2RA', 'ST8SIA4', 'DPF3', 'TP63', 'PAPOLG', 'TP63', 'KALRN', 'ATXN1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqmXPlcfNMoE"
      },
      "source": [
        "To get the adj.p.values under 1E-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYBdQOPgNL6M"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "CVC_risk_genes = pd.read_csv(\"CVC_risk_genes.csv\")\n",
        "CVC_risk_genes_list = []\n",
        "rows = []\n",
        "for index, row in CVC_risk_genes.iterrows():\n",
        "  gene_symbol = row[\"Gene.symbol\"]\n",
        "  p_value = row[\"adj.P.Val\"]\n",
        "  if p_value < 1E-5:\n",
        "    CVC_risk_genes_list.append(gene_symbol)\n",
        "    rows.append(row)\n",
        "\n",
        "\n",
        "#CVC_risk_genes_list = CVC_risk_genes['Gene.symbol'].to_list()\n",
        "rows_df = pd.DataFrame(rows)\n",
        "rows_df.to_csv(\"CVC_genes_52.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chF3PCM-bLqr"
      },
      "source": [
        "Here I will attempt the comparative analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG-sdzSNbKkI",
        "outputId": "824b5188-a76f-417e-a2d1-a483da7a2c71"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "eQTL_genes = pd.read_csv(\"eQTL_Combined.csv\")\n",
        "\n",
        "\"\"\"res = [] \n",
        "top_100_results = []\n",
        "for index, row in eQTL_genes.iterrows():\n",
        "    expressed_gene = row['exp_gene']\n",
        "    if expressed_gene not in res: \n",
        "      res.append(expressed_gene)\n",
        "      top_100_results.append(row)\n",
        "    \n",
        "top_100_results = pd.DataFrame(top_100_results[:1000])\n",
        "top_100_results.to_csv(\"top_1000_eQTL.csv\")\n",
        "\"\"\"\n",
        "\n",
        "CVC_genes = pd.read_csv(\"Top_1000_results.csv\")\n",
        "eQTL_genes = pd.read_csv(\"eQTL_genes_found.csv\")\n",
        "\n",
        "CVC_gene_set = set(CVC_genes[\"0\"].tolist())\n",
        "eQTL_gene_set = set(eQTL_genes[\"exp_gene\"].tolist())\n",
        "\n",
        "CVC_data = pd.read_csv(\"CVC_Combined.csv\")\n",
        "\n",
        "#Check this\n",
        "list_of_overlap = CVC_gene_set.intersection(eQTL_gene_set)\n",
        "print(len(list_of_overlap))\n",
        "print(list_of_overlap)\n",
        "#\n",
        "\n",
        "final_results = []\n",
        "for gene_name in list_of_overlap:\n",
        "  for index, row in CVC_data.iterrows():\n",
        "    expressed_gene = row['Gene.symbol']\n",
        "    if gene_name == expressed_gene:\n",
        "      final_results.append(row)\n",
        "\n",
        "final_results_df = pd.DataFrame(final_results)\n",
        "print(len(final_results_df))\n",
        "final_results_df = final_results_df.sort_values(by=[\"adj.P.Val\"])\n",
        "\n",
        "res = [] \n",
        "final_results_list2 = []\n",
        "for index, row in final_results_df.iterrows():\n",
        "  expressed_gene = row['Gene.symbol']\n",
        "  if expressed_gene not in res: \n",
        "        final_results_list2.append(row) \n",
        "        res.append(expressed_gene)\n",
        "\n",
        "comparative_analysis_results = pd.DataFrame(final_results_list2)\n",
        "comparative_analysis_results = comparative_analysis_results[[\"ID\",\"adj.P.Val\",\"P.Value\",\"t\",\"B\",\"logFC\", \"Gene.symbol\"]]\n",
        "print(len(final_results_list2))\n",
        "print(res)\n",
        "comparative_analysis_results.to_csv(\"Comparative_Analysis_Results.csv\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n",
            "{'BACH2', 'HIPK2', 'STAT1', 'KDM4B', 'KLHL9', 'RNASEH2C', 'ETS1', 'UBE2L3', 'SMARCD1', 'IKZF1', 'CD40', 'IRF7', 'ABCA1', 'LYST', 'JAK2', 'LGALS9', 'RNF114', 'USP18'}\n",
            "91\n",
            "18\n",
            "['JAK2', 'IRF7', 'RNF114', 'IKZF1', 'STAT1', 'HIPK2', 'KDM4B', 'ETS1', 'USP18', 'RNASEH2C', 'LGALS9', 'LYST', 'BACH2', 'UBE2L3', 'CD40', 'ABCA1', 'SMARCD1', 'KLHL9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eW-M16NRaIx"
      },
      "source": [
        "Here we will find the list of genes that overlap from KEGG pathways, Case vs Control analysis, and the eQTL Analysis. These will be studied further in our Literature analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0p9_5mvQYc7",
        "outputId": "c8296109-25a8-47d8-c1af-58539bafb314"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "Kegg_Genes = pd.read_csv(\"KEGG_interesting_mapped.csv\")\n",
        "\n",
        "Kegg_genes_list = Kegg_Genes[\"geneSymbol\"]\n",
        "res_set = set(res)\n",
        "kegg_set = set(Kegg_genes_list)\n",
        "final_list_overlap = res_set.intersection(kegg_set)\n",
        "print(final_list_overlap)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'BACH2', 'KDM4B', 'ETS1', 'UBE2L3', 'CD40', 'IKZF1', 'LYST', 'JAK2', 'HIPK2'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5WVUQHwd0TM"
      },
      "source": [
        "Not using this code or below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji0iz3iY45h2"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "df = pd.read_csv('original_data.csv') \n",
        "df.head()\n",
        "df = df[['SNPS','UPSTREAM_GENE_ID','DOWNSTREAM_GENE_ID','SNP_GENE_IDS','CONTEXT','MAPPED_TRAIT']]\n",
        "df.head()\n",
        "\n",
        "\n",
        "upStreamList = df.UPSTREAM_GENE_ID.tolist()\n",
        "geneNames = []\n",
        "\n",
        "f = open(\"upStreamGeneNames.txt\", \"a\")\n",
        "for item in upStreamList:\n",
        "  if str(item) == 'nan':\n",
        "    pass\n",
        "  else: \n",
        "    if (len(str(item)) > 16):\n",
        "      gene_IDS = str(item)\n",
        "      gene_IDS = gene_IDS.split(\", \")\n",
        "      for thing in gene_IDS:\n",
        "\n",
        "        f.write(str(thing) + \"\\n\")\n",
        "    else: \n",
        "      f.write(str(item) + \"\\n\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3pXQ5L45NBH"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "df = pd.read_csv('original_data.csv') \n",
        "df.head()\n",
        "df = df[['SNPS','UPSTREAM_GENE_ID','DOWNSTREAM_GENE_ID','SNP_GENE_IDS','CONTEXT','MAPPED_TRAIT']]\n",
        "df.head()\n",
        "\n",
        "\n",
        "downStreamList = df.DOWNSTREAM_GENE_ID.tolist()\n",
        "geneNames = []\n",
        "\n",
        "f = open(\"downStreamGeneNames.txt\", \"a\")\n",
        "for item in downStreamList:\n",
        "  if str(item) == 'nan':\n",
        "    pass\n",
        "  else: \n",
        "    if (len(str(item)) > 16):\n",
        "      gene_IDS = str(item)\n",
        "      gene_IDS = gene_IDS.split(\", \")\n",
        "      for thing in gene_IDS:\n",
        "\n",
        "        f.write(str(thing) + \"\\n\")\n",
        "    else: \n",
        "      f.write(str(item) + \"\\n\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3VOGAi644fs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCWQRE9u1rZV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}